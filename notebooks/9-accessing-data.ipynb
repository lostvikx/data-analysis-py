{"cells":[{"cell_type":"markdown","source":[" # Data Loading, Storage, & File Formats"],"metadata":{}},{"cell_type":"markdown","source":[" `pandas` features a number of functions for reading tabular data as a DataFrame object."],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["import pandas as pd\n","import numpy as np\n","import sys\n","import csv\n","import json\n","from lxml import objectify\n","import requests\n","import re\n","import sqlite3\n","import sqlalchemy as sqla"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["ex1 = \"examples/ex1.csv\""],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["! cat $ex1"],"outputs":[{"output_type":"stream","name":"stdout","text":["a,b,c,d,message\n","1,2,3,4,hello\n","5,6,7,8,world\n","9,10,11,12,foo"]}],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["test_df1 = pd.read_csv(ex1)\n","test_df1"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>hello</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   a   b   c   d message\n","0  1   2   3   4   hello\n","1  5   6   7   8   world\n","2  9  10  11  12     foo"]},"metadata":{},"execution_count":4}],"metadata":{}},{"cell_type":"markdown","source":[" Use `header` parameter to set any row as the column labels or `names` to set custom column labels:"],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["# Creates column index [0:)\n","df_col_names = [\"a\", \"b\", \"c\", \"d\", \"message\"]\n","test_df2 = pd.read_csv(\"examples/ex2.csv\", header=None, names=df_col_names)\n","test_df2"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>hello</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   a   b   c   d message\n","0  1   2   3   4   hello\n","1  5   6   7   8   world\n","2  9  10  11  12     foo"]},"metadata":{},"execution_count":5}],"metadata":{}},{"cell_type":"markdown","source":[" Let's say we want the \"message\" column as the index"],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["pd.read_csv(\"examples/ex2.csv\", names=df_col_names, index_col=\"message\")"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","    </tr>\n","    <tr>\n","      <th>message</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>hello</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>world</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>foo</th>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         a   b   c   d\n","message               \n","hello    1   2   3   4\n","world    5   6   7   8\n","foo      9  10  11  12"]},"metadata":{},"execution_count":6}],"metadata":{}},{"cell_type":"markdown","source":[" Hierarchical Index:"],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["pd.read_csv(\"examples/csv_mindex.csv\", index_col=[\"key1\", \"key2\"])"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>value1</th>\n","      <th>value2</th>\n","    </tr>\n","    <tr>\n","      <th>key1</th>\n","      <th>key2</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">one</th>\n","      <th>a</th>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>b</th>\n","      <td>3</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>c</th>\n","      <td>5</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>d</th>\n","      <td>7</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">two</th>\n","      <th>a</th>\n","      <td>9</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>b</th>\n","      <td>11</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>c</th>\n","      <td>13</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>d</th>\n","      <td>15</td>\n","      <td>16</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           value1  value2\n","key1 key2                \n","one  a          1       2\n","     b          3       4\n","     c          5       6\n","     d          7       8\n","two  a          9      10\n","     b         11      12\n","     c         13      14\n","     d         15      16"]},"metadata":{},"execution_count":7}],"metadata":{}},{"cell_type":"markdown","source":[" Some times a table might not have a fixed or use some other delimiter, we can still parse that data:"],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["pd.read_csv(\"examples/ex3.txt\", sep=\"\\s+\")"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>aaa</th>\n","      <td>-0.264438</td>\n","      <td>-1.026059</td>\n","      <td>-0.619500</td>\n","    </tr>\n","    <tr>\n","      <th>bbb</th>\n","      <td>0.927272</td>\n","      <td>0.302904</td>\n","      <td>-0.032399</td>\n","    </tr>\n","    <tr>\n","      <th>ccc</th>\n","      <td>-0.264273</td>\n","      <td>-0.386314</td>\n","      <td>-0.217601</td>\n","    </tr>\n","    <tr>\n","      <th>ddd</th>\n","      <td>-0.871858</td>\n","      <td>-0.348382</td>\n","      <td>1.100491</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            A         B         C\n","aaa -0.264438 -1.026059 -0.619500\n","bbb  0.927272  0.302904 -0.032399\n","ccc -0.264273 -0.386314 -0.217601\n","ddd -0.871858 -0.348382  1.100491"]},"metadata":{},"execution_count":8}],"metadata":{}},{"cell_type":"markdown","source":[" The `sep` argument can take a regular expression as well as a string.\n","\n"," Because there is one fewer column name (first row) than the columns (all other rows), pandas infers the first column as the index."],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["pd.read_csv(\"examples/ex4.csv\", skiprows=[0,2,3])"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>hello</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   a   b   c   d message\n","0  1   2   3   4   hello\n","1  5   6   7   8   world\n","2  9  10  11  12     foo"]},"metadata":{},"execution_count":9}],"metadata":{}},{"cell_type":"markdown","source":[" Handling missing data while reading a file is important. By default, `pandas` parses blank space, or *sentinels* such as NA & NULL."],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["! cat \"examples/ex5.csv\"\n","pd.read_csv(\"examples/ex5.csv\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["something,a,b,c,d,message\n","one,,null,3,4,NA\n","two,5,6,,8,world\n","three,NULL,10,11,12,foo"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>something</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>two</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>three</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>11.0</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  something    a     b     c   d message\n","0       one  NaN   NaN   3.0   4     NaN\n","1       two  5.0   6.0   NaN   8   world\n","2     three  NaN  10.0  11.0  12     foo"]},"metadata":{},"execution_count":10}],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["pd.read_csv(\"examples/ex5.csv\", na_values=[\"foo\"])"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>something</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>two</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>three</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>11.0</td>\n","      <td>12</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  something    a     b     c   d message\n","0       one  NaN   NaN   3.0   4     NaN\n","1       two  5.0   6.0   NaN   8   world\n","2     three  NaN  10.0  11.0  12     NaN"]},"metadata":{},"execution_count":11}],"metadata":{}},{"cell_type":"markdown","source":[" We can add more sentinels by using the `na_values` argument."],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["pd.read_csv(\"examples/ex5.csv\", keep_default_na=False)"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>something</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one</td>\n","      <td></td>\n","      <td>null</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>NA</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>two</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td></td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>three</td>\n","      <td>NULL</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  something     a     b   c   d message\n","0       one        null   3   4      NA\n","1       two     5     6       8   world\n","2     three  NULL    10  11  12     foo"]},"metadata":{},"execution_count":12}],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["df5 = pd.read_csv(\"examples/ex5.csv\", keep_default_na=False, na_values=[\"NA\", \"null\", \"\", \"NULL\"])\n","df5"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>something</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>two</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>three</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>11.0</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  something    a     b     c   d message\n","0       one  NaN   NaN   3.0   4     NaN\n","1       two  5.0   6.0   NaN   8   world\n","2     three  NaN  10.0  11.0  12     foo"]},"metadata":{},"execution_count":13}],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["df5.isna()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>something</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   something      a      b      c      d  message\n","0      False   True   True  False  False     True\n","1      False  False  False   True  False    False\n","2      False   True  False  False  False    False"]},"metadata":{},"execution_count":14}],"metadata":{}},{"cell_type":"markdown","source":[" We can even define sentinels specific to columns:"],"metadata":{}},{"cell_type":"code","execution_count":15,"source":["sentinels = {\n","  \"something\": [\"two\"], \n","  \"message\": [\"foo\"]\n","}\n","pd.read_csv(\"examples/ex5.csv\", na_values=sentinels)"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>something</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>three</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>11.0</td>\n","      <td>12</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  something    a     b     c   d message\n","0       one  NaN   NaN   3.0   4     NaN\n","1       NaN  5.0   6.0   NaN   8   world\n","2     three  NaN  10.0  11.0  12     NaN"]},"metadata":{},"execution_count":15}],"metadata":{}},{"cell_type":"markdown","source":[" ### Reading text (CSV) files in chunks"],"metadata":{}},{"cell_type":"code","execution_count":16,"source":["# Read small piece of a large file:\n","pd.options.display.max_rows = 10"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["pd.read_csv(\"examples/ex6.csv\")"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>one</th>\n","      <th>two</th>\n","      <th>three</th>\n","      <th>four</th>\n","      <th>key</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.467976</td>\n","      <td>-0.038649</td>\n","      <td>-0.295344</td>\n","      <td>-1.824726</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.358893</td>\n","      <td>1.404453</td>\n","      <td>0.704965</td>\n","      <td>-0.200638</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.501840</td>\n","      <td>0.659254</td>\n","      <td>-0.421691</td>\n","      <td>-0.057688</td>\n","      <td>G</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.204886</td>\n","      <td>1.074134</td>\n","      <td>1.388361</td>\n","      <td>-0.982404</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.354628</td>\n","      <td>-0.133116</td>\n","      <td>0.283763</td>\n","      <td>-0.837063</td>\n","      <td>Q</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>2.311896</td>\n","      <td>-0.417070</td>\n","      <td>-1.409599</td>\n","      <td>-0.515821</td>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>-0.479893</td>\n","      <td>-0.650419</td>\n","      <td>0.745152</td>\n","      <td>-0.646038</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>0.523331</td>\n","      <td>0.787112</td>\n","      <td>0.486066</td>\n","      <td>1.093156</td>\n","      <td>K</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>-0.362559</td>\n","      <td>0.598894</td>\n","      <td>-1.843201</td>\n","      <td>0.887292</td>\n","      <td>G</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>-0.096376</td>\n","      <td>-1.012999</td>\n","      <td>-0.657431</td>\n","      <td>-0.573315</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows Ã— 5 columns</p>\n","</div>"],"text/plain":["           one       two     three      four key\n","0     0.467976 -0.038649 -0.295344 -1.824726   L\n","1    -0.358893  1.404453  0.704965 -0.200638   B\n","2    -0.501840  0.659254 -0.421691 -0.057688   G\n","3     0.204886  1.074134  1.388361 -0.982404   R\n","4     0.354628 -0.133116  0.283763 -0.837063   Q\n","...        ...       ...       ...       ...  ..\n","9995  2.311896 -0.417070 -1.409599 -0.515821   L\n","9996 -0.479893 -0.650419  0.745152 -0.646038   E\n","9997  0.523331  0.787112  0.486066  1.093156   K\n","9998 -0.362559  0.598894 -1.843201  0.887292   G\n","9999 -0.096376 -1.012999 -0.657431 -0.573315   0\n","\n","[10000 rows x 5 columns]"]},"metadata":{},"execution_count":17}],"metadata":{}},{"cell_type":"markdown","source":[" Read in chunks of X rows:"],"metadata":{}},{"cell_type":"code","execution_count":18,"source":["df6_chunker = pd.read_csv(\"examples/ex6.csv\", chunksize=1000)\n","key_fq = pd.Series([], dtype=\"int64\") # used later\n","type(df6_chunker)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.io.parsers.readers.TextFileReader"]},"metadata":{},"execution_count":18}],"metadata":{}},{"cell_type":"code","execution_count":19,"source":["for chunk in df6_chunker:\n","  print(chunk)\n","  break"],"outputs":[{"output_type":"stream","name":"stdout","text":["          one       two     three      four key\n","0    0.467976 -0.038649 -0.295344 -1.824726   L\n","1   -0.358893  1.404453  0.704965 -0.200638   B\n","2   -0.501840  0.659254 -0.421691 -0.057688   G\n","3    0.204886  1.074134  1.388361 -0.982404   R\n","4    0.354628 -0.133116  0.283763 -0.837063   Q\n","..        ...       ...       ...       ...  ..\n","995  2.311896 -0.417070 -1.409599 -0.515821   M\n","996 -0.479893 -0.650419  0.745152 -0.646038   H\n","997  0.523331  0.787112  0.486066  1.093156   D\n","998 -0.362559  0.598894 -1.843201  0.887292   W\n","999 -0.096376 -1.012999 -0.657431 -0.573315   K\n","\n","[1000 rows x 5 columns]\n"]}],"metadata":{}},{"cell_type":"markdown","source":[" Or open it as a handler, then iterate over the chunks:"],"metadata":{}},{"cell_type":"code","execution_count":20,"source":["with pd.read_csv(\"examples/ex6.csv\", chunksize=1000) as reader:\n","  # Read chuncksize rows at every iteration\n","  for chunk in reader:\n","    # # Check df\n","    # print(chunk.head())\n","    # break\n","    # Adding series (+), fill_value: key_fq was a blank Series.\n","    key_fq = key_fq.add(chunk[\"key\"].value_counts(), fill_value=0)\n","\n","key_fq"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    151.0\n","1    146.0\n","2    152.0\n","3    162.0\n","4    171.0\n","     ...  \n","V    328.0\n","W    305.0\n","X    364.0\n","Y    314.0\n","Z    288.0\n","Length: 36, dtype: float64"]},"metadata":{},"execution_count":20}],"metadata":{}},{"cell_type":"code","execution_count":22,"source":["with pd.read_csv(\"examples/ex6.csv\", chunksize=1000) as reader:\n","  # Can iterate like: for chunk in reader.get_chunk()\n","  # It's a generater function\n","  print(reader.get_chunk())"],"outputs":[{"output_type":"stream","name":"stdout","text":["          one       two     three      four key\n","0    0.467976 -0.038649 -0.295344 -1.824726   L\n","1   -0.358893  1.404453  0.704965 -0.200638   B\n","2   -0.501840  0.659254 -0.421691 -0.057688   G\n","3    0.204886  1.074134  1.388361 -0.982404   R\n","4    0.354628 -0.133116  0.283763 -0.837063   Q\n","..        ...       ...       ...       ...  ..\n","995  2.311896 -0.417070 -1.409599 -0.515821   M\n","996 -0.479893 -0.650419  0.745152 -0.646038   H\n","997  0.523331  0.787112  0.486066  1.093156   D\n","998 -0.362559  0.598894 -1.843201  0.887292   W\n","999 -0.096376 -1.012999 -0.657431 -0.573315   K\n","\n","[1000 rows x 5 columns]\n"]}],"metadata":{}},{"cell_type":"markdown","source":[" ### Writing out text files"],"metadata":{}},{"cell_type":"code","execution_count":23,"source":["df5"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>something</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>two</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>three</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>11.0</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  something    a     b     c   d message\n","0       one  NaN   NaN   3.0   4     NaN\n","1       two  5.0   6.0   NaN   8   world\n","2     three  NaN  10.0  11.0  12     foo"]},"metadata":{},"execution_count":23}],"metadata":{}},{"cell_type":"code","execution_count":24,"source":["df5.to_csv(\"examples/out.csv\")\n","! cat examples/out.csv"],"outputs":[{"output_type":"stream","name":"stdout","text":[",something,a,b,c,d,message\n","0,one,,,3.0,4,\n","1,two,5.0,6.0,,8,world\n","2,three,,10.0,11.0,12,foo\n"]}],"metadata":{}},{"cell_type":"code","execution_count":25,"source":["# Other delimiters & represent nan values as \"NULL\":\n","df5.to_csv(sys.stdout, sep=\"|\", na_rep=\"NULL\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["|something|a|b|c|d|message\n","0|one|NULL|NULL|3.0|4|NULL\n","1|two|5.0|6.0|NULL|8|world\n","2|three|NULL|10.0|11.0|12|foo\n"]}],"metadata":{}},{"cell_type":"code","execution_count":26,"source":["# Can disable index & headers\n","df5.to_csv(sys.stdout, index=False, header=False) # header = bool or list"],"outputs":[{"output_type":"stream","name":"stdout","text":["one,,,3.0,4,\n","two,5.0,6.0,,8,world\n","three,,10.0,11.0,12,foo\n"]}],"metadata":{}},{"cell_type":"code","execution_count":27,"source":["# Only a subset of cols\n","df5.to_csv(sys.stdout, index=False, columns=[\"a\", \"b\", \"c\"])"],"outputs":[{"output_type":"stream","name":"stdout","text":["a,b,c\n",",,3.0\n","5.0,6.0,\n",",10.0,11.0\n"]}],"metadata":{}},{"cell_type":"code","execution_count":28,"source":["! cat examples/ex7.csv"],"outputs":[{"output_type":"stream","name":"stdout","text":["\"a\",\"b\",\"c\"\n","\"1\",\"2\",\"3\"\n","\"1\",\"2\",\"3\"\n"]}],"metadata":{}},{"cell_type":"code","execution_count":29,"source":["pd.read_csv(\"examples/ex7.csv\")"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   a  b  c\n","0  1  2  3\n","1  1  2  3"]},"metadata":{},"execution_count":29}],"metadata":{}},{"cell_type":"code","execution_count":30,"source":["with open(\"examples/ex7.csv\") as f:\n","  for line in csv.reader(f):\n","    print(line)"],"outputs":[{"output_type":"stream","name":"stdout","text":["['a', 'b', 'c']\n","['1', '2', '3']\n","['1', '2', '3']\n"]}],"metadata":{}},{"cell_type":"code","execution_count":31,"source":["with open(\"examples/ex7.csv\") as f:\n","  lines = list(csv.reader(f))\n","  header, values = lines[0], lines[1:]\n","  data_dict = {h: v for h, v in zip(header, zip(*values))}\n","  print(data_dict)"],"outputs":[{"output_type":"stream","name":"stdout","text":["{'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}\n"]}],"metadata":{}},{"cell_type":"code","execution_count":32,"source":["class custom_dialect(csv.Dialect):\n","  # refer the docs\n","  delimiter = \";\"\n","  lineterminator = \"\\n\"\n","  quotechar = '\"'\n","  quoting = csv.QUOTE_MINIMAL"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":[" Now, we can write a csv file with a custom format, dialect:"],"metadata":{}},{"cell_type":"code","execution_count":33,"source":["with open(\"examples/custom_dialect_file.csv\", \"w\") as file:\n","  writer = csv.writer(file, dialect=custom_dialect)\n","  writer.writerow((\"one\", \"two\", \"three\"))\n","  writer.writerow(tuple(\"123\"))\n","  writer.writerow(tuple(\"456\"))"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":[" ### JSON Files"],"metadata":{}},{"cell_type":"code","execution_count":34,"source":["obj_js = \"\"\"\n","{\n","  \"name\": \"Vikram Negi\",\n","  \"cities_lived\": [\"Navi Mumbai\", \"Mumbai\", \"Dehradun\"],\n","  \"pet\": null,\n","  \"siblings\": [\n","    {\"name\": \"Yogesh\", \"age\": 16, \"hobbies\": [\"gaming\", \"gym\", \"anime\", \"football\"]},\n","    {\"name\": \"Varun\", \"age\": 5, \"hobbies\": [\"reading\", \"gaming\", \"cartoon\"]}\n","  ]\n","}\n","\"\"\"\n","test_js = json.loads(obj_js)\n","test_js"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'name': 'Vikram Negi',\n"," 'cities_lived': ['Navi Mumbai', 'Mumbai', 'Dehradun'],\n"," 'pet': None,\n"," 'siblings': [{'name': 'Yogesh',\n","   'age': 16,\n","   'hobbies': ['gaming', 'gym', 'anime', 'football']},\n","  {'name': 'Varun', 'age': 5, 'hobbies': ['reading', 'gaming', 'cartoon']}]}"]},"metadata":{},"execution_count":34}],"metadata":{}},{"cell_type":"code","execution_count":35,"source":["sibs = pd.DataFrame(test_js[\"siblings\"], columns=[\"name\", \"age\"])\n","sibs"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Yogesh</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Varun</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     name  age\n","0  Yogesh   16\n","1   Varun    5"]},"metadata":{},"execution_count":35}],"metadata":{}},{"cell_type":"code","execution_count":36,"source":["! cat examples/example.json"],"outputs":[{"output_type":"stream","name":"stdout","text":["[{\"a\": 1, \"b\": 2, \"c\": 3},\n"," {\"a\": 4, \"b\": 5, \"c\": 6},\n"," {\"a\": 7, \"b\": 8, \"c\": 9}]\n"]}],"metadata":{}},{"cell_type":"code","execution_count":37,"source":["js = pd.read_json(\"examples/example.json\")\n","js"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   a  b  c\n","0  1  2  3\n","1  4  5  6\n","2  7  8  9"]},"metadata":{},"execution_count":37}],"metadata":{}},{"cell_type":"code","execution_count":38,"source":["js.to_json(sys.stdout)\n","# Or, for array output:\n","js.to_json(sys.stdout, orient=\"records\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["{\"a\":{\"0\":1,\"1\":4,\"2\":7},\"b\":{\"0\":2,\"1\":5,\"2\":8},\"c\":{\"0\":3,\"1\":6,\"2\":9}}[{\"a\":1,\"b\":2,\"c\":3},{\"a\":4,\"b\":5,\"c\":6},{\"a\":7,\"b\":8,\"c\":9}]"]}],"metadata":{}},{"cell_type":"markdown","source":[" ### HTML & XML: Web Scrapping"],"metadata":{}},{"cell_type":"code","execution_count":39,"source":["# Need to install lxml module\n","tables = pd.read_html(\"examples/fdic_failed_bank_list.html\")\n","failed_banks = tables[0]"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":40,"source":["failed_banks.head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Bank Name</th>\n","      <th>City</th>\n","      <th>ST</th>\n","      <th>CERT</th>\n","      <th>Acquiring Institution</th>\n","      <th>Closing Date</th>\n","      <th>Updated Date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Allied Bank</td>\n","      <td>Mulberry</td>\n","      <td>AR</td>\n","      <td>91</td>\n","      <td>Today's Bank</td>\n","      <td>September 23, 2016</td>\n","      <td>November 17, 2016</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The Woodbury Banking Company</td>\n","      <td>Woodbury</td>\n","      <td>GA</td>\n","      <td>11297</td>\n","      <td>United Bank</td>\n","      <td>August 19, 2016</td>\n","      <td>November 17, 2016</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>First CornerStone Bank</td>\n","      <td>King of Prussia</td>\n","      <td>PA</td>\n","      <td>35312</td>\n","      <td>First-Citizens Bank &amp; Trust Company</td>\n","      <td>May 6, 2016</td>\n","      <td>September 6, 2016</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Trust Company Bank</td>\n","      <td>Memphis</td>\n","      <td>TN</td>\n","      <td>9956</td>\n","      <td>The Bank of Fayette County</td>\n","      <td>April 29, 2016</td>\n","      <td>September 6, 2016</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>North Milwaukee State Bank</td>\n","      <td>Milwaukee</td>\n","      <td>WI</td>\n","      <td>20364</td>\n","      <td>First-Citizens Bank &amp; Trust Company</td>\n","      <td>March 11, 2016</td>\n","      <td>June 16, 2016</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      Bank Name             City  ST   CERT  \\\n","0                   Allied Bank         Mulberry  AR     91   \n","1  The Woodbury Banking Company         Woodbury  GA  11297   \n","2        First CornerStone Bank  King of Prussia  PA  35312   \n","3            Trust Company Bank          Memphis  TN   9956   \n","4    North Milwaukee State Bank        Milwaukee  WI  20364   \n","\n","                 Acquiring Institution        Closing Date       Updated Date  \n","0                         Today's Bank  September 23, 2016  November 17, 2016  \n","1                          United Bank     August 19, 2016  November 17, 2016  \n","2  First-Citizens Bank & Trust Company         May 6, 2016  September 6, 2016  \n","3           The Bank of Fayette County      April 29, 2016  September 6, 2016  \n","4  First-Citizens Bank & Trust Company      March 11, 2016      June 16, 2016  "]},"metadata":{},"execution_count":40}],"metadata":{}},{"cell_type":"markdown","source":[" No. of bank failures by year:"],"metadata":{}},{"cell_type":"code","execution_count":41,"source":["closing_timestamps = pd.to_datetime(failed_banks[\"Closing Date\"])\n","closing_timestamps.dt.year.value_counts()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["2010    157\n","2009    140\n","2011     92\n","2012     51\n","2008     25\n","       ... \n","2004      4\n","2001      4\n","2007      3\n","2003      3\n","2000      2\n","Name: Closing Date, Length: 15, dtype: int64"]},"metadata":{},"execution_count":41}],"metadata":{}},{"cell_type":"code","execution_count":42,"source":["with open(\"datasets/mta_perf/Performance_MNR.xml\") as f:\n","  parsed = objectify.parse(f)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":43,"source":["root = parsed.getroot()\n","root"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Element PERFORMANCE at 0x7fbeec9bfb40>"]},"metadata":{},"execution_count":43}],"metadata":{}},{"cell_type":"code","execution_count":44,"source":["xml_data = []\n","skip_fields = (\"INDICATOR_SEQ\", \"PARENT_SEQ\",\n","               \"DESIRED_CHANGE\", \"DECIMAL_PLACES\")\n","\n","for el in root.INDICATOR:\n","  el_data = {}\n","  for child in el.getchildren():\n","    if child.tag not in skip_fields:\n","      # using .pyval instead of .text, because it type converts the values\n","      el_data[child.tag] = child.pyval\n","\n","  if len(el_data) != 0:\n","    xml_data.append(el_data)\n","\n","len(xml_data)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["648"]},"metadata":{},"execution_count":44}],"metadata":{}},{"cell_type":"code","execution_count":45,"source":["xml_df = pd.DataFrame(xml_data)\n","xml_df.head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AGENCY_NAME</th>\n","      <th>INDICATOR_NAME</th>\n","      <th>DESCRIPTION</th>\n","      <th>PERIOD_YEAR</th>\n","      <th>PERIOD_MONTH</th>\n","      <th>CATEGORY</th>\n","      <th>FREQUENCY</th>\n","      <th>INDICATOR_UNIT</th>\n","      <th>YTD_TARGET</th>\n","      <th>YTD_ACTUAL</th>\n","      <th>MONTHLY_TARGET</th>\n","      <th>MONTHLY_ACTUAL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Metro-North Railroad</td>\n","      <td>On-Time Performance (West of Hudson)</td>\n","      <td>Percent of commuter trains that arrive at thei...</td>\n","      <td>2008</td>\n","      <td>1</td>\n","      <td>Service Indicators</td>\n","      <td>M</td>\n","      <td>%</td>\n","      <td>95.0</td>\n","      <td>96.9</td>\n","      <td>95.0</td>\n","      <td>96.9</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Metro-North Railroad</td>\n","      <td>On-Time Performance (West of Hudson)</td>\n","      <td>Percent of commuter trains that arrive at thei...</td>\n","      <td>2008</td>\n","      <td>2</td>\n","      <td>Service Indicators</td>\n","      <td>M</td>\n","      <td>%</td>\n","      <td>95.0</td>\n","      <td>96.0</td>\n","      <td>95.0</td>\n","      <td>95.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Metro-North Railroad</td>\n","      <td>On-Time Performance (West of Hudson)</td>\n","      <td>Percent of commuter trains that arrive at thei...</td>\n","      <td>2008</td>\n","      <td>3</td>\n","      <td>Service Indicators</td>\n","      <td>M</td>\n","      <td>%</td>\n","      <td>95.0</td>\n","      <td>96.3</td>\n","      <td>95.0</td>\n","      <td>96.9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Metro-North Railroad</td>\n","      <td>On-Time Performance (West of Hudson)</td>\n","      <td>Percent of commuter trains that arrive at thei...</td>\n","      <td>2008</td>\n","      <td>4</td>\n","      <td>Service Indicators</td>\n","      <td>M</td>\n","      <td>%</td>\n","      <td>95.0</td>\n","      <td>96.8</td>\n","      <td>95.0</td>\n","      <td>98.3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Metro-North Railroad</td>\n","      <td>On-Time Performance (West of Hudson)</td>\n","      <td>Percent of commuter trains that arrive at thei...</td>\n","      <td>2008</td>\n","      <td>5</td>\n","      <td>Service Indicators</td>\n","      <td>M</td>\n","      <td>%</td>\n","      <td>95.0</td>\n","      <td>96.6</td>\n","      <td>95.0</td>\n","      <td>95.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            AGENCY_NAME                        INDICATOR_NAME  \\\n","0  Metro-North Railroad  On-Time Performance (West of Hudson)   \n","1  Metro-North Railroad  On-Time Performance (West of Hudson)   \n","2  Metro-North Railroad  On-Time Performance (West of Hudson)   \n","3  Metro-North Railroad  On-Time Performance (West of Hudson)   \n","4  Metro-North Railroad  On-Time Performance (West of Hudson)   \n","\n","                                         DESCRIPTION  PERIOD_YEAR  \\\n","0  Percent of commuter trains that arrive at thei...         2008   \n","1  Percent of commuter trains that arrive at thei...         2008   \n","2  Percent of commuter trains that arrive at thei...         2008   \n","3  Percent of commuter trains that arrive at thei...         2008   \n","4  Percent of commuter trains that arrive at thei...         2008   \n","\n","   PERIOD_MONTH            CATEGORY FREQUENCY INDICATOR_UNIT YTD_TARGET  \\\n","0             1  Service Indicators         M              %       95.0   \n","1             2  Service Indicators         M              %       95.0   \n","2             3  Service Indicators         M              %       95.0   \n","3             4  Service Indicators         M              %       95.0   \n","4             5  Service Indicators         M              %       95.0   \n","\n","  YTD_ACTUAL MONTHLY_TARGET MONTHLY_ACTUAL  \n","0       96.9           95.0           96.9  \n","1       96.0           95.0           95.0  \n","2       96.3           95.0           96.9  \n","3       96.8           95.0           98.3  \n","4       96.6           95.0           95.8  "]},"metadata":{},"execution_count":45}],"metadata":{}},{"cell_type":"markdown","source":[" The above data extraction can be done in a single line using `.read_xml` method in pandas:"],"metadata":{}},{"cell_type":"code","execution_count":46,"source":["xml_df2 = pd.read_xml(\"datasets/mta_perf/Performance_MNR.xml\")\n","\n","include_fields = []\n","for field in xml_df2.columns:\n","  if field not in skip_fields:\n","    include_fields.append(field)\n","\n","xml_df2.loc[:, include_fields].head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AGENCY_NAME</th>\n","      <th>INDICATOR_NAME</th>\n","      <th>DESCRIPTION</th>\n","      <th>PERIOD_YEAR</th>\n","      <th>PERIOD_MONTH</th>\n","      <th>CATEGORY</th>\n","      <th>FREQUENCY</th>\n","      <th>INDICATOR_UNIT</th>\n","      <th>YTD_TARGET</th>\n","      <th>YTD_ACTUAL</th>\n","      <th>MONTHLY_TARGET</th>\n","      <th>MONTHLY_ACTUAL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Metro-North Railroad</td>\n","      <td>On-Time Performance (West of Hudson)</td>\n","      <td>Percent of commuter trains that arrive at thei...</td>\n","      <td>2008</td>\n","      <td>1</td>\n","      <td>Service Indicators</td>\n","      <td>M</td>\n","      <td>%</td>\n","      <td>95.00</td>\n","      <td>96.90</td>\n","      <td>95.00</td>\n","      <td>96.90</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Metro-North Railroad</td>\n","      <td>On-Time Performance (West of Hudson)</td>\n","      <td>Percent of commuter trains that arrive at thei...</td>\n","      <td>2008</td>\n","      <td>2</td>\n","      <td>Service Indicators</td>\n","      <td>M</td>\n","      <td>%</td>\n","      <td>95.00</td>\n","      <td>96.00</td>\n","      <td>95.00</td>\n","      <td>95.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Metro-North Railroad</td>\n","      <td>On-Time Performance (West of Hudson)</td>\n","      <td>Percent of commuter trains that arrive at thei...</td>\n","      <td>2008</td>\n","      <td>3</td>\n","      <td>Service Indicators</td>\n","      <td>M</td>\n","      <td>%</td>\n","      <td>95.00</td>\n","      <td>96.30</td>\n","      <td>95.00</td>\n","      <td>96.90</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Metro-North Railroad</td>\n","      <td>On-Time Performance (West of Hudson)</td>\n","      <td>Percent of commuter trains that arrive at thei...</td>\n","      <td>2008</td>\n","      <td>4</td>\n","      <td>Service Indicators</td>\n","      <td>M</td>\n","      <td>%</td>\n","      <td>95.00</td>\n","      <td>96.80</td>\n","      <td>95.00</td>\n","      <td>98.30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Metro-North Railroad</td>\n","      <td>On-Time Performance (West of Hudson)</td>\n","      <td>Percent of commuter trains that arrive at thei...</td>\n","      <td>2008</td>\n","      <td>5</td>\n","      <td>Service Indicators</td>\n","      <td>M</td>\n","      <td>%</td>\n","      <td>95.00</td>\n","      <td>96.60</td>\n","      <td>95.00</td>\n","      <td>95.80</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            AGENCY_NAME                        INDICATOR_NAME  \\\n","0  Metro-North Railroad  On-Time Performance (West of Hudson)   \n","1  Metro-North Railroad  On-Time Performance (West of Hudson)   \n","2  Metro-North Railroad  On-Time Performance (West of Hudson)   \n","3  Metro-North Railroad  On-Time Performance (West of Hudson)   \n","4  Metro-North Railroad  On-Time Performance (West of Hudson)   \n","\n","                                         DESCRIPTION  PERIOD_YEAR  \\\n","0  Percent of commuter trains that arrive at thei...         2008   \n","1  Percent of commuter trains that arrive at thei...         2008   \n","2  Percent of commuter trains that arrive at thei...         2008   \n","3  Percent of commuter trains that arrive at thei...         2008   \n","4  Percent of commuter trains that arrive at thei...         2008   \n","\n","   PERIOD_MONTH            CATEGORY FREQUENCY INDICATOR_UNIT YTD_TARGET  \\\n","0             1  Service Indicators         M              %      95.00   \n","1             2  Service Indicators         M              %      95.00   \n","2             3  Service Indicators         M              %      95.00   \n","3             4  Service Indicators         M              %      95.00   \n","4             5  Service Indicators         M              %      95.00   \n","\n","  YTD_ACTUAL MONTHLY_TARGET MONTHLY_ACTUAL  \n","0      96.90          95.00          96.90  \n","1      96.00          95.00          95.00  \n","2      96.30          95.00          96.90  \n","3      96.80          95.00          98.30  \n","4      96.60          95.00          95.80  "]},"metadata":{},"execution_count":46}],"metadata":{}},{"cell_type":"markdown","source":[" ### Binary Data Format"],"metadata":{}},{"cell_type":"code","execution_count":47,"source":["# Method 1: Pickle format\n","df_1 = pd.read_csv(\"examples/ex1.csv\")\n","df_1"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>hello</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   a   b   c   d message\n","0  1   2   3   4   hello\n","1  5   6   7   8   world\n","2  9  10  11  12     foo"]},"metadata":{},"execution_count":47}],"metadata":{}},{"cell_type":"code","execution_count":48,"source":["df_1.to_pickle(\"examples/ex_pickle\")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":49,"source":["pd.read_pickle(\"examples/ex_pickle\")"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>hello</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   a   b   c   d message\n","0  1   2   3   4   hello\n","1  5   6   7   8   world\n","2  9  10  11  12     foo"]},"metadata":{},"execution_count":49}],"metadata":{}},{"cell_type":"markdown","source":[" `pickle` is only recommended as a short-term storage format, because it may not be supported in the future version of python."],"metadata":{}},{"cell_type":"markdown","source":[" ### Excel files"],"metadata":{}},{"cell_type":"code","execution_count":50,"source":["# Used when multiple sheets in an xlsx file\n","xlsx = pd.ExcelFile(\"examples/ex1.xlsx\")\n","excel_sheet_name = xlsx.sheet_names[0]\n","xlsx.parse(excel_sheet_name, index_col=0)"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>hello</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   a   b   c   d message\n","0  1   2   3   4   hello\n","1  5   6   7   8   world\n","2  9  10  11  12     foo"]},"metadata":{},"execution_count":50}],"metadata":{}},{"cell_type":"code","execution_count":51,"source":["# OR simply use read_excel\n","xl_frame = pd.read_excel(\"examples/ex1.xlsx\", sheet_name=excel_sheet_name, index_col=0)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":[" Similarly there are two ways to write data to an excel file:"],"metadata":{}},{"cell_type":"code","execution_count":52,"source":["xlsx_writer = pd.ExcelWriter(\"examples/ex2.xlsx\")\n","xl_frame.to_excel(xlsx_writer, \"Sheet1\")\n","xlsx_writer.save()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":53,"source":["pd.read_excel(\"examples/ex2.xlsx\", sheet_name=\"Sheet1\", index_col=0)"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>hello</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>foo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   a   b   c   d message\n","0  1   2   3   4   hello\n","1  5   6   7   8   world\n","2  9  10  11  12     foo"]},"metadata":{},"execution_count":53}],"metadata":{}},{"cell_type":"markdown","source":[" ### Hierarchial Data Format\n","\n"," First install `tables` package"],"metadata":{}},{"cell_type":"code","execution_count":54,"source":["test_df = pd.DataFrame(np.random.standard_normal((100,5))*5, columns=list(\"abcde\"))\n","test_df.head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.606668</td>\n","      <td>5.449402</td>\n","      <td>-0.728420</td>\n","      <td>3.286665</td>\n","      <td>-4.803210</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-3.372551</td>\n","      <td>-1.206116</td>\n","      <td>5.507383</td>\n","      <td>-2.990513</td>\n","      <td>-0.031590</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.204594</td>\n","      <td>2.803767</td>\n","      <td>-4.137105</td>\n","      <td>0.371271</td>\n","      <td>4.814977</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-1.220577</td>\n","      <td>-11.397113</td>\n","      <td>-1.823349</td>\n","      <td>1.215034</td>\n","      <td>-1.821504</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1.242612</td>\n","      <td>-2.628863</td>\n","      <td>-3.530020</td>\n","      <td>-3.065260</td>\n","      <td>7.033785</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          a          b         c         d         e\n","0  5.606668   5.449402 -0.728420  3.286665 -4.803210\n","1 -3.372551  -1.206116  5.507383 -2.990513 -0.031590\n","2 -2.204594   2.803767 -4.137105  0.371271  4.814977\n","3 -1.220577 -11.397113 -1.823349  1.215034 -1.821504\n","4 -1.242612  -2.628863 -3.530020 -3.065260  7.033785"]},"metadata":{},"execution_count":54}],"metadata":{}},{"cell_type":"code","execution_count":55,"source":["# Store class\n","store = pd.HDFStore(\"examples/test.h5\")\n","store"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<class 'pandas.io.pytables.HDFStore'>\n","File path: examples/test.h5"]},"metadata":{},"execution_count":55}],"metadata":{}},{"cell_type":"code","execution_count":56,"source":["store[\"test_1\"] = test_df # store DataFrame\n","store[\"col_a\"] = test_df[\"a\"] # store Series"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":57,"source":["store[\"test_1\"].head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.606668</td>\n","      <td>5.449402</td>\n","      <td>-0.728420</td>\n","      <td>3.286665</td>\n","      <td>-4.803210</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-3.372551</td>\n","      <td>-1.206116</td>\n","      <td>5.507383</td>\n","      <td>-2.990513</td>\n","      <td>-0.031590</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.204594</td>\n","      <td>2.803767</td>\n","      <td>-4.137105</td>\n","      <td>0.371271</td>\n","      <td>4.814977</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-1.220577</td>\n","      <td>-11.397113</td>\n","      <td>-1.823349</td>\n","      <td>1.215034</td>\n","      <td>-1.821504</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1.242612</td>\n","      <td>-2.628863</td>\n","      <td>-3.530020</td>\n","      <td>-3.065260</td>\n","      <td>7.033785</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          a          b         c         d         e\n","0  5.606668   5.449402 -0.728420  3.286665 -4.803210\n","1 -3.372551  -1.206116  5.507383 -2.990513 -0.031590\n","2 -2.204594   2.803767 -4.137105  0.371271  4.814977\n","3 -1.220577 -11.397113 -1.823349  1.215034 -1.821504\n","4 -1.242612  -2.628863 -3.530020 -3.065260  7.033785"]},"metadata":{},"execution_count":57}],"metadata":{}},{"cell_type":"markdown","source":[" `HDFStore` supports two storage schemas (format), \"`fixed`\" & \"`table`\"\n","\n"," * Default is `fixed`\n"," * `table` is slower, but supports query operations using special syntax"],"metadata":{}},{"cell_type":"code","execution_count":58,"source":["# put is the same as assigning store[\"key_name\"] = df, but allows for defining\n","# specific format\n","store.put(\"test_2\", test_df, format=\"table\")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":59,"source":["# Query it kinda like a database\n","store.select(\"test_2\", where=[\"index >= 10 and index < 15\"])"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10</th>\n","      <td>1.506609</td>\n","      <td>-4.751056</td>\n","      <td>-9.368857</td>\n","      <td>-5.356335</td>\n","      <td>-3.575709</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>-5.942064</td>\n","      <td>2.519561</td>\n","      <td>-0.150001</td>\n","      <td>-5.999577</td>\n","      <td>-2.481324</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>6.554236</td>\n","      <td>-1.262817</td>\n","      <td>-1.697952</td>\n","      <td>3.749887</td>\n","      <td>4.184971</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>5.071260</td>\n","      <td>-3.113428</td>\n","      <td>1.511293</td>\n","      <td>-1.518928</td>\n","      <td>-7.893768</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>-1.236928</td>\n","      <td>-0.061157</td>\n","      <td>0.252540</td>\n","      <td>-8.637764</td>\n","      <td>4.939822</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           a         b         c         d         e\n","10  1.506609 -4.751056 -9.368857 -5.356335 -3.575709\n","11 -5.942064  2.519561 -0.150001 -5.999577 -2.481324\n","12  6.554236 -1.262817 -1.697952  3.749887  4.184971\n","13  5.071260 -3.113428  1.511293 -1.518928 -7.893768\n","14 -1.236928 -0.061157  0.252540 -8.637764  4.939822"]},"metadata":{},"execution_count":59}],"metadata":{}},{"cell_type":"markdown","source":[" Here is a simple way to do read & write HDF:"],"metadata":{}},{"cell_type":"code","execution_count":61,"source":["# Write operation\n","test_df.to_hdf(\"examples/test2.h5\", \"test\", format=\"table\")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":62,"source":["# Read operation\n","pd.read_hdf(\"examples/test2.h5\", \"test\", where=[\"index < 5\"])"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.606668</td>\n","      <td>5.449402</td>\n","      <td>-0.728420</td>\n","      <td>3.286665</td>\n","      <td>-4.803210</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-3.372551</td>\n","      <td>-1.206116</td>\n","      <td>5.507383</td>\n","      <td>-2.990513</td>\n","      <td>-0.031590</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.204594</td>\n","      <td>2.803767</td>\n","      <td>-4.137105</td>\n","      <td>0.371271</td>\n","      <td>4.814977</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-1.220577</td>\n","      <td>-11.397113</td>\n","      <td>-1.823349</td>\n","      <td>1.215034</td>\n","      <td>-1.821504</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1.242612</td>\n","      <td>-2.628863</td>\n","      <td>-3.530020</td>\n","      <td>-3.065260</td>\n","      <td>7.033785</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          a          b         c         d         e\n","0  5.606668   5.449402 -0.728420  3.286665 -4.803210\n","1 -3.372551  -1.206116  5.507383 -2.990513 -0.031590\n","2 -2.204594   2.803767 -4.137105  0.371271  4.814977\n","3 -1.220577 -11.397113 -1.823349  1.215034 -1.821504\n","4 -1.242612  -2.628863 -3.530020 -3.065260  7.033785"]},"metadata":{},"execution_count":62}],"metadata":{}},{"cell_type":"markdown","source":[" **Note**: `HDF5` isn't a database. It's best suited for write-once, read-many datasets."],"metadata":{}},{"cell_type":"markdown","source":[" ### Interacting with Web APIs"],"metadata":{}},{"cell_type":"code","execution_count":63,"source":["reddit_tiktok_url = \"https://www.reddit.com/r/TikTokCringe/top.json?limit=10\"\n","headers = {\"user-agent\": \"Linux Machine (Vikram Singh Negi)\"}\n","\n","res = requests.get(reddit_tiktok_url, headers=headers)\n","try:\n","  res.raise_for_status()\n","  data = res.json()[\"data\"]\n","except Exception as err:\n","  print(f\"HTTP Error: {err}\")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":64,"source":["# pd.DataFrame([child[\"data\"] for child in data[\"children\"]])\n","[child[\"data\"] for child in data[\"children\"]][0]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'approved_at_utc': None,\n"," 'subreddit': 'TikTokCringe',\n"," 'selftext': '',\n"," 'author_fullname': 't2_6wdexyp2',\n"," 'saved': False,\n"," 'mod_reason_title': None,\n"," 'gilded': 0,\n"," 'clicked': False,\n"," 'title': 'New dress',\n"," 'link_flair_richtext': [],\n"," 'subreddit_name_prefixed': 'r/TikTokCringe',\n"," 'hidden': False,\n"," 'pwls': 7,\n"," 'link_flair_css_class': '',\n"," 'downs': 0,\n"," 'thumbnail_height': 140,\n"," 'top_awarded_type': None,\n"," 'hide_score': False,\n"," 'name': 't3_vvvjgv',\n"," 'quarantine': False,\n"," 'link_flair_text_color': 'light',\n"," 'upvote_ratio': 0.92,\n"," 'author_flair_background_color': None,\n"," 'ups': 21103,\n"," 'total_awards_received': 1,\n"," 'media_embed': {},\n"," 'thumbnail_width': 140,\n"," 'author_flair_template_id': None,\n"," 'is_original_content': False,\n"," 'user_reports': [],\n"," 'secure_media': {'reddit_video': {'bitrate_kbps': 2400,\n","   'fallback_url': 'https://v.redd.it/a1v6p2lvrra91/DASH_720.mp4?source=fallback',\n","   'height': 720,\n","   'width': 405,\n","   'scrubber_media_url': 'https://v.redd.it/a1v6p2lvrra91/DASH_96.mp4',\n","   'dash_url': 'https://v.redd.it/a1v6p2lvrra91/DASHPlaylist.mpd?a=1660118903%2CZTY1ZTU1ZmNmMTc0NTU5N2ZjYjExOTE5N2FjNGE0YjgyYmQzN2I2ZTEyMThkZTUyNDViZWQ4ZmUxNThiNTBiNw%3D%3D&amp;v=1&amp;f=hd',\n","   'duration': 12,\n","   'hls_url': 'https://v.redd.it/a1v6p2lvrra91/HLSPlaylist.m3u8?a=1660118903%2CZWY0ZmVmOGI3M2YxZmQ2N2JiNjQzZDk2ZjZmZjJhOGE4MGYxZTM0MDcwOGI5MjcwNDY5OTA3NDdhYTAyNzRiNw%3D%3D&amp;v=1&amp;f=hd',\n","   'is_gif': False,\n","   'transcoding_status': 'completed'}},\n"," 'is_reddit_media_domain': True,\n"," 'is_meta': False,\n"," 'category': None,\n"," 'secure_media_embed': {},\n"," 'link_flair_text': 'Humor',\n"," 'can_mod_post': False,\n"," 'score': 21103,\n"," 'approved_by': None,\n"," 'is_created_from_ads_ui': False,\n"," 'author_premium': True,\n"," 'thumbnail': 'https://b.thumbs.redditmedia.com/nb4y_Vh1bXGUYwxaq1a43stR3CX_OYGq5KEaqkvOgGE.jpg',\n"," 'edited': False,\n"," 'author_flair_css_class': None,\n"," 'author_flair_richtext': [],\n"," 'gildings': {'gid_1': 1},\n"," 'post_hint': 'hosted:video',\n"," 'content_categories': None,\n"," 'is_self': False,\n"," 'subreddit_type': 'public',\n"," 'created': 1657471646.0,\n"," 'link_flair_type': 'text',\n"," 'wls': 7,\n"," 'removed_by_category': None,\n"," 'banned_by': None,\n"," 'author_flair_type': 'text',\n"," 'domain': 'v.redd.it',\n"," 'allow_live_comments': True,\n"," 'selftext_html': None,\n"," 'likes': None,\n"," 'suggested_sort': None,\n"," 'banned_at_utc': None,\n"," 'url_overridden_by_dest': 'https://v.redd.it/a1v6p2lvrra91',\n"," 'view_count': None,\n"," 'archived': False,\n"," 'no_follow': False,\n"," 'is_crosspostable': False,\n"," 'pinned': False,\n"," 'over_18': False,\n"," 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/6jmqkQeZ6TPxWvCuJ17cfrMhyHlIJ_n00MVVWKMoPO4.png?format=pjpg&amp;auto=webp&amp;s=07e4e2e31cb87b2436dfaa10f15d17c05350ec7b',\n","     'width': 576,\n","     'height': 1024},\n","    'resolutions': [{'url': 'https://external-preview.redd.it/6jmqkQeZ6TPxWvCuJ17cfrMhyHlIJ_n00MVVWKMoPO4.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=639038cc95385cfcabab195677614d5d8aa689fd',\n","      'width': 108,\n","      'height': 192},\n","     {'url': 'https://external-preview.redd.it/6jmqkQeZ6TPxWvCuJ17cfrMhyHlIJ_n00MVVWKMoPO4.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=835fd4c32a99950da220915b2e87aaf7f5b75cb2',\n","      'width': 216,\n","      'height': 384},\n","     {'url': 'https://external-preview.redd.it/6jmqkQeZ6TPxWvCuJ17cfrMhyHlIJ_n00MVVWKMoPO4.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a4abc685572230172eef57d7dd0fb41f7c4d6032',\n","      'width': 320,\n","      'height': 568}],\n","    'variants': {},\n","    'id': 'A9TeoaVDEezkvcFZn9gdDO147e-Euow_u4b0RbvmW6A'}],\n","  'enabled': False},\n"," 'all_awardings': [{'giver_coin_reward': None,\n","   'subreddit_id': None,\n","   'is_new': False,\n","   'days_of_drip_extension': None,\n","   'coin_price': 100,\n","   'id': 'gid_1',\n","   'penny_donate': None,\n","   'award_sub_type': 'GLOBAL',\n","   'coin_reward': 0,\n","   'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png',\n","   'days_of_premium': None,\n","   'tiers_by_required_awardings': None,\n","   'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png',\n","     'width': 16,\n","     'height': 16},\n","    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png',\n","     'width': 32,\n","     'height': 32},\n","    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png',\n","     'width': 48,\n","     'height': 48},\n","    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png',\n","     'width': 64,\n","     'height': 64},\n","    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png',\n","     'width': 128,\n","     'height': 128}],\n","   'icon_width': 512,\n","   'static_icon_width': 512,\n","   'start_date': None,\n","   'is_enabled': True,\n","   'awardings_required_to_grant_benefits': None,\n","   'description': \"Shows the Silver Award... and that's it.\",\n","   'end_date': None,\n","   'sticky_duration_seconds': None,\n","   'subreddit_coin_reward': 0,\n","   'count': 1,\n","   'static_icon_height': 512,\n","   'name': 'Silver',\n","   'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png',\n","     'width': 16,\n","     'height': 16},\n","    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png',\n","     'width': 32,\n","     'height': 32},\n","    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png',\n","     'width': 48,\n","     'height': 48},\n","    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png',\n","     'width': 64,\n","     'height': 64},\n","    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png',\n","     'width': 128,\n","     'height': 128}],\n","   'icon_format': None,\n","   'icon_height': 512,\n","   'penny_price': None,\n","   'award_type': 'global',\n","   'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}],\n"," 'awarders': [],\n"," 'media_only': False,\n"," 'link_flair_template_id': '234c4f7c-5c6e-11e9-95b9-0e3466d98bbe',\n"," 'can_gild': False,\n"," 'spoiler': False,\n"," 'locked': False,\n"," 'author_flair_text': None,\n"," 'treatment_tags': [],\n"," 'visited': False,\n"," 'removed_by': None,\n"," 'mod_note': None,\n"," 'distinguished': None,\n"," 'subreddit_id': 't5_mvcq5',\n"," 'author_is_blocked': False,\n"," 'mod_reason_by': None,\n"," 'num_reports': None,\n"," 'removal_reason': None,\n"," 'link_flair_background_color': '#24a0ed',\n"," 'id': 'vvvjgv',\n"," 'is_robot_indexable': True,\n"," 'report_reasons': None,\n"," 'author': 'lilmcfuggin',\n"," 'discussion_type': None,\n"," 'num_comments': 215,\n"," 'send_replies': False,\n"," 'whitelist_status': 'some_ads',\n"," 'contest_mode': False,\n"," 'mod_reports': [],\n"," 'author_patreon_flair': False,\n"," 'author_flair_text_color': None,\n"," 'permalink': '/r/TikTokCringe/comments/vvvjgv/new_dress/',\n"," 'parent_whitelist_status': 'some_ads',\n"," 'stickied': False,\n"," 'url': 'https://v.redd.it/a1v6p2lvrra91',\n"," 'subreddit_subscribers': 1272095,\n"," 'created_utc': 1657471646.0,\n"," 'num_crossposts': 2,\n"," 'media': {'reddit_video': {'bitrate_kbps': 2400,\n","   'fallback_url': 'https://v.redd.it/a1v6p2lvrra91/DASH_720.mp4?source=fallback',\n","   'height': 720,\n","   'width': 405,\n","   'scrubber_media_url': 'https://v.redd.it/a1v6p2lvrra91/DASH_96.mp4',\n","   'dash_url': 'https://v.redd.it/a1v6p2lvrra91/DASHPlaylist.mpd?a=1660118903%2CZTY1ZTU1ZmNmMTc0NTU5N2ZjYjExOTE5N2FjNGE0YjgyYmQzN2I2ZTEyMThkZTUyNDViZWQ4ZmUxNThiNTBiNw%3D%3D&amp;v=1&amp;f=hd',\n","   'duration': 12,\n","   'hls_url': 'https://v.redd.it/a1v6p2lvrra91/HLSPlaylist.m3u8?a=1660118903%2CZWY0ZmVmOGI3M2YxZmQ2N2JiNjQzZDk2ZjZmZjJhOGE4MGYxZTM0MDcwOGI5MjcwNDY5OTA3NDdhYTAyNzRiNw%3D%3D&amp;v=1&amp;f=hd',\n","   'is_gif': False,\n","   'transcoding_status': 'completed'}},\n"," 'is_video': True}"]},"metadata":{},"execution_count":64}],"metadata":{}},{"cell_type":"code","execution_count":65,"source":["dt = []\n","valid_fields = [\"subreddit\", \"title\", \"thumbnail\", \"url_overridden_by_dest\", \"subreddit_id\", \"author\", \"url\", \"media\", \"is_video\"]\n","\n","for child in data[\"children\"]:\n","  if child[\"data\"][\"is_video\"]:\n","    child_data = {}\n","    for key, val in child[\"data\"].items():\n","      if key in valid_fields:\n","        if key == \"media\":\n","          fallback_url = val[\"reddit_video\"][\"fallback_url\"]\n","          child_data[\"video_url\"] = fallback_url\n","          child_data[\"audio_url\"] = re.sub(r\"[\\w+\\/]DASH_(\\d+)\", \"/DASH_audio\", fallback_url)\n","        else:\n","          child_data[key] = val\n","    dt.append(child_data)\n","\n","pd.DataFrame(dt)"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>subreddit</th>\n","      <th>title</th>\n","      <th>thumbnail</th>\n","      <th>url_overridden_by_dest</th>\n","      <th>subreddit_id</th>\n","      <th>author</th>\n","      <th>url</th>\n","      <th>video_url</th>\n","      <th>audio_url</th>\n","      <th>is_video</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TikTokCringe</td>\n","      <td>New dress</td>\n","      <td>https://b.thumbs.redditmedia.com/nb4y_Vh1bXGUY...</td>\n","      <td>https://v.redd.it/a1v6p2lvrra91</td>\n","      <td>t5_mvcq5</td>\n","      <td>lilmcfuggin</td>\n","      <td>https://v.redd.it/a1v6p2lvrra91</td>\n","      <td>https://v.redd.it/a1v6p2lvrra91/DASH_720.mp4?s...</td>\n","      <td>https://v.redd.it/a1v6p2lvrra91/DASH_audio.mp4...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TikTokCringe</td>\n","      <td>Why does this remind me of the purge.</td>\n","      <td>https://a.thumbs.redditmedia.com/jwKt35ny--rp4...</td>\n","      <td>https://v.redd.it/syfpj2y0rta91</td>\n","      <td>t5_mvcq5</td>\n","      <td>_ElReaper</td>\n","      <td>https://v.redd.it/syfpj2y0rta91</td>\n","      <td>https://v.redd.it/syfpj2y0rta91/DASH_360.mp4?s...</td>\n","      <td>https://v.redd.it/syfpj2y0rta91/DASH_audio.mp4...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TikTokCringe</td>\n","      <td>Sisters pregnant at the same time</td>\n","      <td>https://a.thumbs.redditmedia.com/lmxVX7Vzg6KH4...</td>\n","      <td>https://v.redd.it/vw7jf6vz4ta91</td>\n","      <td>t5_mvcq5</td>\n","      <td>bigdickjenny</td>\n","      <td>https://v.redd.it/vw7jf6vz4ta91</td>\n","      <td>https://v.redd.it/vw7jf6vz4ta91/DASH_1080.mp4?...</td>\n","      <td>https://v.redd.it/vw7jf6vz4ta91/DASH_audio.mp4...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TikTokCringe</td>\n","      <td>The two brain cells trying to form together ðŸ˜‚ ...</td>\n","      <td>https://a.thumbs.redditmedia.com/34pwq5a0OTunX...</td>\n","      <td>https://v.redd.it/z52y2vzwrsa91</td>\n","      <td>t5_mvcq5</td>\n","      <td>megami96</td>\n","      <td>https://v.redd.it/z52y2vzwrsa91</td>\n","      <td>https://v.redd.it/z52y2vzwrsa91/DASH_720.mp4?s...</td>\n","      <td>https://v.redd.it/z52y2vzwrsa91/DASH_audio.mp4...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TikTokCringe</td>\n","      <td>She was NOT pleased!</td>\n","      <td>https://b.thumbs.redditmedia.com/4lGGyPYO679Z7...</td>\n","      <td>https://v.redd.it/4r2wjfd5rua91</td>\n","      <td>t5_mvcq5</td>\n","      <td>WaterEnvironmental80</td>\n","      <td>https://v.redd.it/4r2wjfd5rua91</td>\n","      <td>https://v.redd.it/4r2wjfd5rua91/DASH_720.mp4?s...</td>\n","      <td>https://v.redd.it/4r2wjfd5rua91/DASH_audio.mp4...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>TikTokCringe</td>\n","      <td>Bear encounters a mirror</td>\n","      <td>https://b.thumbs.redditmedia.com/OIxZNt0FqnBTX...</td>\n","      <td>https://v.redd.it/7if2610fjqa91</td>\n","      <td>t5_mvcq5</td>\n","      <td>LeSpatula</td>\n","      <td>https://v.redd.it/7if2610fjqa91</td>\n","      <td>https://v.redd.it/7if2610fjqa91/DASH_480.mp4?s...</td>\n","      <td>https://v.redd.it/7if2610fjqa91/DASH_audio.mp4...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>TikTokCringe</td>\n","      <td>How To Make Buttermilk Biscuits</td>\n","      <td>https://b.thumbs.redditmedia.com/HKV9bwB-FEAO3...</td>\n","      <td>https://v.redd.it/pkal0mnx8sa91</td>\n","      <td>t5_mvcq5</td>\n","      <td>Artistic-Audience182</td>\n","      <td>https://v.redd.it/pkal0mnx8sa91</td>\n","      <td>https://v.redd.it/pkal0mnx8sa91/DASH_1080.mp4?...</td>\n","      <td>https://v.redd.it/pkal0mnx8sa91/DASH_audio.mp4...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>TikTokCringe</td>\n","      <td>Natural hair</td>\n","      <td>https://a.thumbs.redditmedia.com/EgjEc7FcFDj_V...</td>\n","      <td>https://v.redd.it/mm2zcrmesra91</td>\n","      <td>t5_mvcq5</td>\n","      <td>lilmcfuggin</td>\n","      <td>https://v.redd.it/mm2zcrmesra91</td>\n","      <td>https://v.redd.it/mm2zcrmesra91/DASH_720.mp4?s...</td>\n","      <td>https://v.redd.it/mm2zcrmesra91/DASH_audio.mp4...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>TikTokCringe</td>\n","      <td>Attempting to pick on a bassist</td>\n","      <td>https://b.thumbs.redditmedia.com/CjU3gqkdDVBKr...</td>\n","      <td>https://v.redd.it/iwj5g7ikvpa91</td>\n","      <td>t5_mvcq5</td>\n","      <td>EndVry</td>\n","      <td>https://v.redd.it/iwj5g7ikvpa91</td>\n","      <td>https://v.redd.it/iwj5g7ikvpa91/DASH_720.mp4?s...</td>\n","      <td>https://v.redd.it/iwj5g7ikvpa91/DASH_audio.mp4...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>TikTokCringe</td>\n","      <td>Cubert the attention hog</td>\n","      <td>https://b.thumbs.redditmedia.com/VC6Po2zTjJHU6...</td>\n","      <td>https://v.redd.it/jxsptjl9sra91</td>\n","      <td>t5_mvcq5</td>\n","      <td>lilmcfuggin</td>\n","      <td>https://v.redd.it/jxsptjl9sra91</td>\n","      <td>https://v.redd.it/jxsptjl9sra91/DASH_720.mp4?s...</td>\n","      <td>https://v.redd.it/jxsptjl9sra91/DASH_audio.mp4...</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      subreddit                                              title  \\\n","0  TikTokCringe                                          New dress   \n","1  TikTokCringe              Why does this remind me of the purge.   \n","2  TikTokCringe                  Sisters pregnant at the same time   \n","3  TikTokCringe  The two brain cells trying to form together ðŸ˜‚ ...   \n","4  TikTokCringe                               She was NOT pleased!   \n","5  TikTokCringe                           Bear encounters a mirror   \n","6  TikTokCringe                    How To Make Buttermilk Biscuits   \n","7  TikTokCringe                                       Natural hair   \n","8  TikTokCringe                    Attempting to pick on a bassist   \n","9  TikTokCringe                           Cubert the attention hog   \n","\n","                                           thumbnail  \\\n","0  https://b.thumbs.redditmedia.com/nb4y_Vh1bXGUY...   \n","1  https://a.thumbs.redditmedia.com/jwKt35ny--rp4...   \n","2  https://a.thumbs.redditmedia.com/lmxVX7Vzg6KH4...   \n","3  https://a.thumbs.redditmedia.com/34pwq5a0OTunX...   \n","4  https://b.thumbs.redditmedia.com/4lGGyPYO679Z7...   \n","5  https://b.thumbs.redditmedia.com/OIxZNt0FqnBTX...   \n","6  https://b.thumbs.redditmedia.com/HKV9bwB-FEAO3...   \n","7  https://a.thumbs.redditmedia.com/EgjEc7FcFDj_V...   \n","8  https://b.thumbs.redditmedia.com/CjU3gqkdDVBKr...   \n","9  https://b.thumbs.redditmedia.com/VC6Po2zTjJHU6...   \n","\n","            url_overridden_by_dest subreddit_id                author  \\\n","0  https://v.redd.it/a1v6p2lvrra91     t5_mvcq5           lilmcfuggin   \n","1  https://v.redd.it/syfpj2y0rta91     t5_mvcq5             _ElReaper   \n","2  https://v.redd.it/vw7jf6vz4ta91     t5_mvcq5          bigdickjenny   \n","3  https://v.redd.it/z52y2vzwrsa91     t5_mvcq5              megami96   \n","4  https://v.redd.it/4r2wjfd5rua91     t5_mvcq5  WaterEnvironmental80   \n","5  https://v.redd.it/7if2610fjqa91     t5_mvcq5             LeSpatula   \n","6  https://v.redd.it/pkal0mnx8sa91     t5_mvcq5  Artistic-Audience182   \n","7  https://v.redd.it/mm2zcrmesra91     t5_mvcq5           lilmcfuggin   \n","8  https://v.redd.it/iwj5g7ikvpa91     t5_mvcq5                EndVry   \n","9  https://v.redd.it/jxsptjl9sra91     t5_mvcq5           lilmcfuggin   \n","\n","                               url  \\\n","0  https://v.redd.it/a1v6p2lvrra91   \n","1  https://v.redd.it/syfpj2y0rta91   \n","2  https://v.redd.it/vw7jf6vz4ta91   \n","3  https://v.redd.it/z52y2vzwrsa91   \n","4  https://v.redd.it/4r2wjfd5rua91   \n","5  https://v.redd.it/7if2610fjqa91   \n","6  https://v.redd.it/pkal0mnx8sa91   \n","7  https://v.redd.it/mm2zcrmesra91   \n","8  https://v.redd.it/iwj5g7ikvpa91   \n","9  https://v.redd.it/jxsptjl9sra91   \n","\n","                                           video_url  \\\n","0  https://v.redd.it/a1v6p2lvrra91/DASH_720.mp4?s...   \n","1  https://v.redd.it/syfpj2y0rta91/DASH_360.mp4?s...   \n","2  https://v.redd.it/vw7jf6vz4ta91/DASH_1080.mp4?...   \n","3  https://v.redd.it/z52y2vzwrsa91/DASH_720.mp4?s...   \n","4  https://v.redd.it/4r2wjfd5rua91/DASH_720.mp4?s...   \n","5  https://v.redd.it/7if2610fjqa91/DASH_480.mp4?s...   \n","6  https://v.redd.it/pkal0mnx8sa91/DASH_1080.mp4?...   \n","7  https://v.redd.it/mm2zcrmesra91/DASH_720.mp4?s...   \n","8  https://v.redd.it/iwj5g7ikvpa91/DASH_720.mp4?s...   \n","9  https://v.redd.it/jxsptjl9sra91/DASH_720.mp4?s...   \n","\n","                                           audio_url  is_video  \n","0  https://v.redd.it/a1v6p2lvrra91/DASH_audio.mp4...      True  \n","1  https://v.redd.it/syfpj2y0rta91/DASH_audio.mp4...      True  \n","2  https://v.redd.it/vw7jf6vz4ta91/DASH_audio.mp4...      True  \n","3  https://v.redd.it/z52y2vzwrsa91/DASH_audio.mp4...      True  \n","4  https://v.redd.it/4r2wjfd5rua91/DASH_audio.mp4...      True  \n","5  https://v.redd.it/7if2610fjqa91/DASH_audio.mp4...      True  \n","6  https://v.redd.it/pkal0mnx8sa91/DASH_audio.mp4...      True  \n","7  https://v.redd.it/mm2zcrmesra91/DASH_audio.mp4...      True  \n","8  https://v.redd.it/iwj5g7ikvpa91/DASH_audio.mp4...      True  \n","9  https://v.redd.it/jxsptjl9sra91/DASH_audio.mp4...      True  "]},"metadata":{},"execution_count":65}],"metadata":{}},{"cell_type":"markdown","source":[" ### Interacting with Databases"],"metadata":{}},{"cell_type":"code","execution_count":66,"source":["con = sqlite3.connect(\"examples/test.db\")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":67,"source":["create_table_query = \"\"\"\n","  CREATE TABLE us_cities (\n","    city VARCHAR(20),\n","    state VARCHAR(20),\n","    population REAL,\n","    rating INTEGER\n","  )\n","\"\"\"\n","try:\n","  con.execute(create_table_query)\n","  con.commit()\n","except Exception as err:\n","  print(\"DB Error:\", err)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":68,"source":["db_data = [\n","  (\"Atlanta\", \"Georgia\", 1.25, 6),\n","  (\"Tallahassee\", \"Florida\", 2.6, 3),\n","  (\"Sacramento\", \"California\", 1.7, 5)\n","]\n","\n","con.executemany(\"INSERT INTO us_cities VALUES (?, ?, ?, ?)\", db_data)\n","con.commit()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":[" Read from database:"],"metadata":{}},{"cell_type":"code","execution_count":69,"source":["cur = con.execute(\"SELECT * FROM us_cities\")\n","rows = cur.fetchall()\n","rows"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Atlanta', 'Georgia', 1.25, 6),\n"," ('Tallahassee', 'Florida', 2.6, 3),\n"," ('Sacramento', 'California', 1.7, 5)]"]},"metadata":{},"execution_count":69}],"metadata":{}},{"cell_type":"code","execution_count":70,"source":["cur.description"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(('city', None, None, None, None, None, None),\n"," ('state', None, None, None, None, None, None),\n"," ('population', None, None, None, None, None, None),\n"," ('rating', None, None, None, None, None, None))"]},"metadata":{},"execution_count":70}],"metadata":{}},{"cell_type":"code","execution_count":71,"source":["pd.DataFrame(rows, columns=[name[0] for name in cur.description])"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>city</th>\n","      <th>state</th>\n","      <th>population</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Atlanta</td>\n","      <td>Georgia</td>\n","      <td>1.25</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Tallahassee</td>\n","      <td>Florida</td>\n","      <td>2.60</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sacramento</td>\n","      <td>California</td>\n","      <td>1.70</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          city       state  population  rating\n","0      Atlanta     Georgia        1.25       6\n","1  Tallahassee     Florida        2.60       3\n","2   Sacramento  California        1.70       5"]},"metadata":{},"execution_count":71}],"metadata":{}},{"cell_type":"markdown","source":[" Using SQLAlchemy to make the above process simple:"],"metadata":{}},{"cell_type":"code","execution_count":72,"source":["db = sqla.create_engine(\"sqlite:///examples/test.db\")\n","pd.read_sql(\"SELECT * FROM us_cities\", db)"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>city</th>\n","      <th>state</th>\n","      <th>population</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Atlanta</td>\n","      <td>Georgia</td>\n","      <td>1.25</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Tallahassee</td>\n","      <td>Florida</td>\n","      <td>2.60</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sacramento</td>\n","      <td>California</td>\n","      <td>1.70</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          city       state  population  rating\n","0      Atlanta     Georgia        1.25       6\n","1  Tallahassee     Florida        2.60       3\n","2   Sacramento  California        1.70       5"]},"metadata":{},"execution_count":72}],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}